{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1372</td>\n",
       "      <td>ans802.txt</td>\n",
       "      <td>It seems that previously you had an intercosta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>771</td>\n",
       "      <td>a61367.txt</td>\n",
       "      <td>the best way to relax is to put on quiet music...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>ans70.txt</td>\n",
       "      <td>Achilles tendonitis is an inflammation of the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>ans377.txt</td>\n",
       "      <td>Home pregnancy test and especially EPTs are fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>ans1100.txt</td>\n",
       "      <td>Taking stool softeners and milk of magnesia at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>ans1493.txt</td>\n",
       "      <td>The symptoms that you are experiencing such as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1112</td>\n",
       "      <td>ans1143.txt</td>\n",
       "      <td>Thank you for your question. Given your condit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1329</td>\n",
       "      <td>ans1431.txt</td>\n",
       "      <td>The pain in one side of the tongue could be a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>a24793.txt</td>\n",
       "      <td>There is quite a history on them. Please check...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>a31632.txt</td>\n",
       "      <td>Already Answered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>a24853.txt</td>\n",
       "      <td>While living in Paris, my wife was really pert...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>ans183.txt</td>\n",
       "      <td>Chemical like bleach lead to a skin reaction c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>ans1470.txt</td>\n",
       "      <td>The sharp pain that you are experiencing in yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>ans1414.txt</td>\n",
       "      <td>The most probably cause of your burning sensat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>ans1663.txt</td>\n",
       "      <td>Ultrasound dating scans are fairly accurate if...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>ans1346.txt</td>\n",
       "      <td>The foreskin may be stuck due to the developme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>ans1810.txt</td>\n",
       "      <td>Your description most likely corresponds to a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>a61234.txt</td>\n",
       "      <td>Happiness cant be bought. Being drunk is not m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  class\n",
       "1372   ans802.txt  It seems that previously you had an intercosta...      1\n",
       "771    a61367.txt  the best way to relax is to put on quiet music...      0\n",
       "1428    ans70.txt  Achilles tendonitis is an inflammation of the ...      1\n",
       "133    ans377.txt  Home pregnancy test and especially EPTs are fa...      1\n",
       "331   ans1100.txt  Taking stool softeners and milk of magnesia at...      1\n",
       "1649  ans1493.txt  The symptoms that you are experiencing such as...      1\n",
       "1112  ans1143.txt  Thank you for your question. Given your condit...      1\n",
       "1329  ans1431.txt  The pain in one side of the tongue could be a ...      1\n",
       "1055   a24793.txt  There is quite a history on them. Please check...      0\n",
       "803    a31632.txt                                  Already Answered       0\n",
       "44     a24853.txt  While living in Paris, my wife was really pert...      0\n",
       "1496   ans183.txt  Chemical like bleach lead to a skin reaction c...      1\n",
       "307   ans1470.txt  The sharp pain that you are experiencing in yo...      1\n",
       "465   ans1414.txt  The most probably cause of your burning sensat...      1\n",
       "218   ans1663.txt  Ultrasound dating scans are fairly accurate if...      1\n",
       "962   ans1346.txt  The foreskin may be stuck due to the developme...      1\n",
       "882   ans1810.txt  Your description most likely corresponds to a ...      1\n",
       "1040   a61234.txt  Happiness cant be bought. Being drunk is not m...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding='utf-8', errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfnonpro = data2df('HealthProNonPro/NonPro/', 0) \n",
    "dfpro = data2df('HealthProNonPro/Pro/', 1) \n",
    "\n",
    "df = pd.concat([dfnonpro,dfpro], axis=0)\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data\n",
    "X, y = df['text'], df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "def preprocess(text):\n",
    "    # replace one or more white-space characters with a space\n",
    "    regex = re.compile(r\"\\s+\")                               \n",
    "    text = regex.sub(' ', text)    \n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub(' ', text)           \n",
    "    # remove stop words\n",
    "    sw = stopwords.words('english')\n",
    "    text = text.split()                                              \n",
    "    text = ' '.join([w for w in text if w not in sw]) \n",
    "    # remove short words\n",
    "    ' '.join([w for w in text.split() if len(w) >= 2])\n",
    "    # stem\n",
    "    # text = ' '.join([(PorterStemmer()).stem(w) for w in text.split()])\n",
    "    # lemmatize\n",
    "    text = ' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "    return text\n",
    "\n",
    "Xtrain = [preprocess(text) for text in Xtrain]\n",
    "Xtest = [preprocess(text) for text in Xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # clean up text\n",
    "    tokens = [token.lemma_.lower() # lemmatize and lower-case \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are 2 or more characters long\n",
    "                                    #token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve specific pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab\n",
    "                                    #token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop # get rid of tokens that are stop words\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "nlpXtrain = nlp.pipe(Xtrain)\n",
    "nlpXtest = nlp.pipe(Xtest)\n",
    "Xtrain = [custom_tokenizer(doc) for doc in nlpXtrain]\n",
    "Xtest = [custom_tokenizer(doc) for doc in nlpXtest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "  \n",
    "clf = Pipeline(steps=[\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid search\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__sublinear_tf': [True, False], \n",
    "    'nb__alpha':np.linspace(1.0,1.5)\n",
    "}\n",
    "gscv = GridSearchCV(clf, param_grid, cv=4, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('nb',\n",
      "                 MultinomialNB(alpha=1.010204081632653, class_prior=None,\n",
      "                               fit_prior=True))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.9286202185792349 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'nb__alpha': 1.010204081632653, 'tfidf__sublinear_tf': False} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'mean_fit_time': array([0.1387192 , 0.11421835, 0.1233995 , 0.10957092, 0.11582851,\n",
      "       0.11711955, 0.13296449, 0.11482161, 0.11726773, 0.11121172,\n",
      "       0.1555267 , 0.28135312, 0.16887546, 0.20554423, 0.18356764,\n",
      "       0.18145597, 0.20185679, 0.14500123, 0.14896899, 0.13104469,\n",
      "       0.11756921, 0.15922976, 0.12441999, 0.1225515 , 0.14841574,\n",
      "       0.12609476, 0.11485749, 0.11529762, 0.1453957 , 0.13822472,\n",
      "       0.12113053, 0.10787255, 0.13990021, 0.14558882, 0.12519997,\n",
      "       0.1290952 , 0.13796139, 0.16721398, 0.13568908, 0.17138481,\n",
      "       0.1713528 , 0.13620871, 0.1866439 , 0.12082928, 0.12197381,\n",
      "       0.09899902, 0.10123378, 0.09811503, 0.10620046, 0.1021747 ,\n",
      "       0.112095  , 0.11648542, 0.10476083, 0.09915948, 0.10608238,\n",
      "       0.10274398, 0.10280323, 0.09714246, 0.1013881 , 0.09852123,\n",
      "       0.10093784, 0.09835988, 0.10203594, 0.09744412, 0.10097289,\n",
      "       0.11732674, 0.13578725, 0.11469156, 0.15205276, 0.13262248,\n",
      "       0.1447106 , 0.14757895, 0.15431839, 0.154329  , 0.13553727,\n",
      "       0.11310971, 0.15174353, 0.13590336, 0.12065101, 0.12576795,\n",
      "       0.14392078, 0.10289663, 0.13477856, 0.11187702, 0.14697897,\n",
      "       0.11497062, 0.1299929 , 0.1013    , 0.10028261, 0.11138564,\n",
      "       0.10057193, 0.09831619, 0.10072768, 0.09824276, 0.10019761,\n",
      "       0.09979206, 0.10087174, 0.09643847, 0.11860824, 0.12845498]), 'std_fit_time': array([0.01175427, 0.00681558, 0.00627639, 0.00163121, 0.00440068,\n",
      "       0.0199436 , 0.00971453, 0.00892608, 0.00205637, 0.00541611,\n",
      "       0.03390955, 0.17403347, 0.03611795, 0.03071603, 0.02558755,\n",
      "       0.05690304, 0.06078547, 0.03271448, 0.04666165, 0.02051869,\n",
      "       0.00755461, 0.03288333, 0.02391424, 0.01033719, 0.02661747,\n",
      "       0.02072702, 0.01003155, 0.01448403, 0.02384235, 0.02941923,\n",
      "       0.0142322 , 0.0022219 , 0.02350937, 0.03518518, 0.0154219 ,\n",
      "       0.0195324 , 0.01738685, 0.03270876, 0.01991303, 0.01945345,\n",
      "       0.04529253, 0.02680621, 0.01611291, 0.03178936, 0.02500556,\n",
      "       0.00358567, 0.00405924, 0.00212386, 0.00766461, 0.007832  ,\n",
      "       0.01251974, 0.00733581, 0.00256668, 0.00334693, 0.00734464,\n",
      "       0.00935752, 0.00474915, 0.00324786, 0.00421527, 0.00574548,\n",
      "       0.00406073, 0.00403076, 0.00301505, 0.00267382, 0.00461609,\n",
      "       0.01943297, 0.01670338, 0.02350134, 0.02427834, 0.02967056,\n",
      "       0.02865249, 0.00570135, 0.00416735, 0.01808723, 0.01743239,\n",
      "       0.00927571, 0.00895522, 0.02205102, 0.01568691, 0.02544477,\n",
      "       0.02453532, 0.00726619, 0.02930583, 0.01314258, 0.02398992,\n",
      "       0.02653759, 0.04590004, 0.00528656, 0.00387239, 0.02696271,\n",
      "       0.00388944, 0.00511096, 0.00397028, 0.00325747, 0.00413359,\n",
      "       0.00546851, 0.0044399 , 0.00304758, 0.01833296, 0.01681408]), 'mean_score_time': array([0.04021323, 0.03157121, 0.03812748, 0.03418702, 0.03668767,\n",
      "       0.03598344, 0.04067504, 0.03531867, 0.0350669 , 0.03104979,\n",
      "       0.04752326, 0.0847404 , 0.05347759, 0.05723   , 0.05762494,\n",
      "       0.05891329, 0.0839625 , 0.039774  , 0.04360229, 0.03753746,\n",
      "       0.03888941, 0.04193199, 0.04309553, 0.03850377, 0.05102152,\n",
      "       0.03307539, 0.03413951, 0.034262  , 0.05370539, 0.03372103,\n",
      "       0.03502715, 0.03273648, 0.05156839, 0.03898197, 0.04553026,\n",
      "       0.03741527, 0.0545311 , 0.05000013, 0.04557174, 0.04710376,\n",
      "       0.05620897, 0.03702545, 0.0634346 , 0.03440559, 0.03797686,\n",
      "       0.03130817, 0.03132325, 0.02969837, 0.04083323, 0.03026927,\n",
      "       0.03922307, 0.03020179, 0.03177518, 0.03020155, 0.03134215,\n",
      "       0.03065759, 0.03144622, 0.02951676, 0.03123438, 0.02949321,\n",
      "       0.03126508, 0.02952957, 0.03230578, 0.0293768 , 0.03196943,\n",
      "       0.04415637, 0.04572773, 0.03106922, 0.05535495, 0.03816092,\n",
      "       0.04697472, 0.0413987 , 0.05088097, 0.04550129, 0.04283273,\n",
      "       0.03287774, 0.05010968, 0.03725392, 0.03536421, 0.03750163,\n",
      "       0.04658657, 0.03365368, 0.03857946, 0.03640747, 0.03983384,\n",
      "       0.03084928, 0.03118205, 0.03171653, 0.03100705, 0.02990907,\n",
      "       0.03102529, 0.02912217, 0.03120351, 0.02932274, 0.03109598,\n",
      "       0.03040808, 0.03099173, 0.0292908 , 0.03403276, 0.05385035]), 'std_score_time': array([0.00802143, 0.00123874, 0.0044309 , 0.00071009, 0.00242018,\n",
      "       0.00732353, 0.00250035, 0.00165652, 0.00149444, 0.00213526,\n",
      "       0.00523625, 0.05722145, 0.01371074, 0.01866422, 0.00613727,\n",
      "       0.02914157, 0.05230627, 0.00830963, 0.00626028, 0.00591289,\n",
      "       0.00350776, 0.0083892 , 0.01089234, 0.00492024, 0.01065853,\n",
      "       0.00398666, 0.00302565, 0.00123055, 0.00259537, 0.00450993,\n",
      "       0.00185702, 0.00304423, 0.01129319, 0.00871568, 0.01392733,\n",
      "       0.00849492, 0.00251661, 0.01739411, 0.00909238, 0.00440917,\n",
      "       0.02077778, 0.00586723, 0.00623843, 0.00693915, 0.00894408,\n",
      "       0.00247847, 0.00133232, 0.00144304, 0.00604382, 0.00279017,\n",
      "       0.00944698, 0.00343221, 0.00155287, 0.00118001, 0.00100559,\n",
      "       0.00337287, 0.00155549, 0.00184103, 0.00076195, 0.00153501,\n",
      "       0.00127439, 0.0015799 , 0.00272133, 0.00174382, 0.00225576,\n",
      "       0.00644191, 0.01341655, 0.00239226, 0.0078878 , 0.00862507,\n",
      "       0.00961811, 0.00597892, 0.00203764, 0.00889294, 0.01032394,\n",
      "       0.00191173, 0.00288331, 0.00699361, 0.00422219, 0.00759147,\n",
      "       0.00983155, 0.00408047, 0.0107347 , 0.0080896 , 0.01134276,\n",
      "       0.00225671, 0.00100775, 0.00522519, 0.00126866, 0.00270208,\n",
      "       0.0012016 , 0.00150362, 0.00066221, 0.00142659, 0.00132838,\n",
      "       0.00342513, 0.00116017, 0.00147152, 0.00172838, 0.02823192]), 'param_nb__alpha': masked_array(data=[1.0, 1.0, 1.010204081632653, 1.010204081632653,\n",
      "                   1.0204081632653061, 1.0204081632653061,\n",
      "                   1.030612244897959, 1.030612244897959,\n",
      "                   1.0408163265306123, 1.0408163265306123,\n",
      "                   1.0510204081632653, 1.0510204081632653,\n",
      "                   1.0612244897959184, 1.0612244897959184,\n",
      "                   1.0714285714285714, 1.0714285714285714,\n",
      "                   1.0816326530612246, 1.0816326530612246,\n",
      "                   1.0918367346938775, 1.0918367346938775,\n",
      "                   1.1020408163265305, 1.1020408163265305,\n",
      "                   1.1122448979591837, 1.1122448979591837,\n",
      "                   1.1224489795918366, 1.1224489795918366,\n",
      "                   1.1326530612244898, 1.1326530612244898,\n",
      "                   1.1428571428571428, 1.1428571428571428,\n",
      "                   1.153061224489796, 1.153061224489796,\n",
      "                   1.163265306122449, 1.163265306122449,\n",
      "                   1.1734693877551021, 1.1734693877551021,\n",
      "                   1.183673469387755, 1.183673469387755,\n",
      "                   1.193877551020408, 1.193877551020408,\n",
      "                   1.2040816326530612, 1.2040816326530612,\n",
      "                   1.2142857142857142, 1.2142857142857142,\n",
      "                   1.2244897959183674, 1.2244897959183674,\n",
      "                   1.2346938775510203, 1.2346938775510203,\n",
      "                   1.2448979591836735, 1.2448979591836735,\n",
      "                   1.2551020408163265, 1.2551020408163265,\n",
      "                   1.2653061224489797, 1.2653061224489797,\n",
      "                   1.2755102040816326, 1.2755102040816326,\n",
      "                   1.2857142857142856, 1.2857142857142856,\n",
      "                   1.2959183673469388, 1.2959183673469388,\n",
      "                   1.3061224489795917, 1.3061224489795917,\n",
      "                   1.316326530612245, 1.316326530612245,\n",
      "                   1.3265306122448979, 1.3265306122448979,\n",
      "                   1.336734693877551, 1.336734693877551,\n",
      "                   1.346938775510204, 1.346938775510204,\n",
      "                   1.3571428571428572, 1.3571428571428572,\n",
      "                   1.3673469387755102, 1.3673469387755102,\n",
      "                   1.3775510204081631, 1.3775510204081631,\n",
      "                   1.3877551020408163, 1.3877551020408163,\n",
      "                   1.3979591836734693, 1.3979591836734693,\n",
      "                   1.4081632653061225, 1.4081632653061225,\n",
      "                   1.4183673469387754, 1.4183673469387754,\n",
      "                   1.4285714285714286, 1.4285714285714286,\n",
      "                   1.4387755102040816, 1.4387755102040816,\n",
      "                   1.4489795918367347, 1.4489795918367347,\n",
      "                   1.4591836734693877, 1.4591836734693877,\n",
      "                   1.4693877551020407, 1.4693877551020407,\n",
      "                   1.4795918367346939, 1.4795918367346939,\n",
      "                   1.489795918367347, 1.489795918367347, 1.5, 1.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__sublinear_tf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False, True, False, True, False,\n",
      "                   True, False, True, False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'nb__alpha': 1.0, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.010204081632653, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.010204081632653, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0204081632653061, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0204081632653061, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.030612244897959, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.030612244897959, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0408163265306123, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0408163265306123, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0510204081632653, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0510204081632653, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0612244897959184, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0612244897959184, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0714285714285714, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0714285714285714, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0816326530612246, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0816326530612246, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.0918367346938775, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.0918367346938775, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1020408163265305, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1020408163265305, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1122448979591837, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1122448979591837, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1224489795918366, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1224489795918366, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1326530612244898, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1326530612244898, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1428571428571428, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1428571428571428, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.153061224489796, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.153061224489796, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.163265306122449, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.163265306122449, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.1734693877551021, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.1734693877551021, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.183673469387755, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.183673469387755, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.193877551020408, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.193877551020408, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2040816326530612, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2040816326530612, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2142857142857142, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2142857142857142, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2244897959183674, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2244897959183674, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2346938775510203, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2346938775510203, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2448979591836735, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2448979591836735, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2551020408163265, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2551020408163265, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2653061224489797, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2653061224489797, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2755102040816326, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2755102040816326, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2857142857142856, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2857142857142856, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.2959183673469388, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.2959183673469388, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3061224489795917, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3061224489795917, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.316326530612245, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.316326530612245, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3265306122448979, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3265306122448979, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.336734693877551, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.336734693877551, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.346938775510204, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.346938775510204, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3571428571428572, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3571428571428572, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3673469387755102, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3673469387755102, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3775510204081631, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3775510204081631, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3877551020408163, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3877551020408163, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.3979591836734693, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.3979591836734693, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4081632653061225, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4081632653061225, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4183673469387754, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4183673469387754, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4285714285714286, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4285714285714286, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4387755102040816, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4387755102040816, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4489795918367347, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4489795918367347, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4591836734693877, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4591836734693877, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4693877551020407, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4693877551020407, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.4795918367346939, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.4795918367346939, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.489795918367347, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.489795918367347, 'tfidf__sublinear_tf': False}, {'nb__alpha': 1.5, 'tfidf__sublinear_tf': True}, {'nb__alpha': 1.5, 'tfidf__sublinear_tf': False}], 'split0_test_score': array([0.93306011, 0.93852459, 0.93306011, 0.93852459, 0.93306011,\n",
      "       0.93852459, 0.93306011, 0.93579235, 0.93306011, 0.93579235,\n",
      "       0.93306011, 0.93579235, 0.93306011, 0.93579235, 0.93306011,\n",
      "       0.93579235, 0.93306011, 0.93442623, 0.93306011, 0.93442623,\n",
      "       0.93306011, 0.93442623, 0.93306011, 0.93442623, 0.93169399,\n",
      "       0.93442623, 0.93169399, 0.93442623, 0.93169399, 0.93442623,\n",
      "       0.93169399, 0.93442623, 0.93032787, 0.93306011, 0.92896175,\n",
      "       0.93306011, 0.92896175, 0.93169399, 0.92896175, 0.93169399,\n",
      "       0.92896175, 0.93169399, 0.92896175, 0.93169399, 0.92622951,\n",
      "       0.93169399, 0.92622951, 0.93032787, 0.92622951, 0.93032787,\n",
      "       0.92622951, 0.92896175, 0.92486339, 0.92896175, 0.92486339,\n",
      "       0.92896175, 0.92486339, 0.92896175, 0.92486339, 0.92896175,\n",
      "       0.92486339, 0.92896175, 0.92349727, 0.92896175, 0.92349727,\n",
      "       0.92896175, 0.92349727, 0.92896175, 0.92349727, 0.92896175,\n",
      "       0.92349727, 0.92896175, 0.92349727, 0.92896175, 0.92349727,\n",
      "       0.92896175, 0.92349727, 0.92896175, 0.92349727, 0.92896175,\n",
      "       0.92349727, 0.92896175, 0.92349727, 0.92759563, 0.92349727,\n",
      "       0.92759563, 0.92349727, 0.92759563, 0.92349727, 0.92759563,\n",
      "       0.92349727, 0.92759563, 0.92349727, 0.92759563, 0.92349727,\n",
      "       0.92759563, 0.92349727, 0.92759563, 0.92349727, 0.92759563]), 'split1_test_score': array([0.93306011, 0.93306011, 0.93306011, 0.93306011, 0.93306011,\n",
      "       0.93306011, 0.93306011, 0.93306011, 0.93306011, 0.93306011,\n",
      "       0.93306011, 0.93306011, 0.93306011, 0.93306011, 0.93306011,\n",
      "       0.93306011, 0.93306011, 0.93306011, 0.93306011, 0.93306011,\n",
      "       0.93306011, 0.93306011, 0.93306011, 0.93169399, 0.93306011,\n",
      "       0.93169399, 0.93306011, 0.93169399, 0.93306011, 0.93169399,\n",
      "       0.93306011, 0.93169399, 0.93306011, 0.93169399, 0.93169399,\n",
      "       0.93169399, 0.93169399, 0.93169399, 0.93169399, 0.93169399,\n",
      "       0.93169399, 0.93169399, 0.93169399, 0.93169399, 0.93169399,\n",
      "       0.93169399, 0.93169399, 0.93032787, 0.93169399, 0.93032787,\n",
      "       0.93169399, 0.93032787, 0.93169399, 0.93032787, 0.93169399,\n",
      "       0.93032787, 0.93169399, 0.93032787, 0.93032787, 0.93032787,\n",
      "       0.93032787, 0.93032787, 0.93032787, 0.93032787, 0.93032787,\n",
      "       0.93032787, 0.93032787, 0.93032787, 0.93032787, 0.93032787,\n",
      "       0.93032787, 0.93032787, 0.93032787, 0.93032787, 0.93032787,\n",
      "       0.93169399, 0.93032787, 0.93169399, 0.93032787, 0.93169399,\n",
      "       0.92896175, 0.93169399, 0.92896175, 0.93169399, 0.92896175,\n",
      "       0.93169399, 0.92896175, 0.93169399, 0.92896175, 0.93169399,\n",
      "       0.92896175, 0.93032787, 0.92896175, 0.93032787, 0.92896175,\n",
      "       0.93032787, 0.92896175, 0.93032787, 0.92896175, 0.93032787]), 'split2_test_score': array([0.92213115, 0.91939891, 0.92213115, 0.92076503, 0.92213115,\n",
      "       0.92076503, 0.92076503, 0.92076503, 0.92076503, 0.92076503,\n",
      "       0.92076503, 0.92076503, 0.91939891, 0.92076503, 0.91939891,\n",
      "       0.92076503, 0.91939891, 0.92076503, 0.91939891, 0.92076503,\n",
      "       0.91939891, 0.92076503, 0.91939891, 0.92076503, 0.91939891,\n",
      "       0.92076503, 0.91939891, 0.92076503, 0.92076503, 0.92076503,\n",
      "       0.92076503, 0.92076503, 0.92076503, 0.92076503, 0.92076503,\n",
      "       0.92076503, 0.92076503, 0.92076503, 0.92076503, 0.92213115,\n",
      "       0.92076503, 0.92213115, 0.92076503, 0.92213115, 0.92076503,\n",
      "       0.92213115, 0.92076503, 0.92213115, 0.92076503, 0.92213115,\n",
      "       0.92076503, 0.92213115, 0.92076503, 0.92213115, 0.91803279,\n",
      "       0.92213115, 0.91803279, 0.92213115, 0.91803279, 0.92213115,\n",
      "       0.91803279, 0.92213115, 0.91803279, 0.92213115, 0.91803279,\n",
      "       0.92213115, 0.91803279, 0.92076503, 0.91803279, 0.92076503,\n",
      "       0.91803279, 0.92076503, 0.91803279, 0.92076503, 0.91803279,\n",
      "       0.91939891, 0.91803279, 0.91939891, 0.91666667, 0.91939891,\n",
      "       0.91666667, 0.91939891, 0.91666667, 0.91939891, 0.91666667,\n",
      "       0.91939891, 0.91666667, 0.91939891, 0.91666667, 0.91939891,\n",
      "       0.91530055, 0.91939891, 0.91530055, 0.91939891, 0.91530055,\n",
      "       0.91939891, 0.91530055, 0.91939891, 0.91530055, 0.91939891]), 'split3_test_score': array([0.91803279, 0.92213115, 0.91803279, 0.92213115, 0.91803279,\n",
      "       0.92213115, 0.91803279, 0.92076503, 0.91803279, 0.91939891,\n",
      "       0.91803279, 0.91939891, 0.91666667, 0.91939891, 0.91666667,\n",
      "       0.91939891, 0.91666667, 0.91939891, 0.91666667, 0.91939891,\n",
      "       0.91666667, 0.91939891, 0.91666667, 0.91939891, 0.91666667,\n",
      "       0.91939891, 0.91666667, 0.91939891, 0.91530055, 0.91803279,\n",
      "       0.91530055, 0.91803279, 0.91530055, 0.91803279, 0.91530055,\n",
      "       0.91803279, 0.91530055, 0.91666667, 0.91530055, 0.91666667,\n",
      "       0.91530055, 0.91666667, 0.91530055, 0.91666667, 0.91530055,\n",
      "       0.91666667, 0.91530055, 0.91530055, 0.91530055, 0.91530055,\n",
      "       0.91530055, 0.91530055, 0.91530055, 0.91256831, 0.91530055,\n",
      "       0.91120219, 0.91530055, 0.91120219, 0.91530055, 0.91120219,\n",
      "       0.91666667, 0.91120219, 0.91666667, 0.91120219, 0.91666667,\n",
      "       0.91120219, 0.91666667, 0.91120219, 0.91666667, 0.91120219,\n",
      "       0.91666667, 0.91120219, 0.91666667, 0.91120219, 0.91530055,\n",
      "       0.91120219, 0.91530055, 0.91120219, 0.91120219, 0.91120219,\n",
      "       0.91120219, 0.91120219, 0.91120219, 0.91120219, 0.91120219,\n",
      "       0.91120219, 0.91120219, 0.91120219, 0.91120219, 0.91120219,\n",
      "       0.91120219, 0.90983607, 0.90983607, 0.90983607, 0.90983607,\n",
      "       0.90983607, 0.90983607, 0.90983607, 0.90983607, 0.90983607]), 'mean_test_score': array([0.92657104, 0.92827869, 0.92657104, 0.92862022, 0.92657104,\n",
      "       0.92862022, 0.92622951, 0.92759563, 0.92622951, 0.9272541 ,\n",
      "       0.92622951, 0.9272541 , 0.92554645, 0.9272541 , 0.92554645,\n",
      "       0.9272541 , 0.92554645, 0.92691257, 0.92554645, 0.92691257,\n",
      "       0.92554645, 0.92691257, 0.92554645, 0.92657104, 0.92520492,\n",
      "       0.92657104, 0.92520492, 0.92657104, 0.92520492, 0.92622951,\n",
      "       0.92520492, 0.92622951, 0.92486339, 0.92588798, 0.92418033,\n",
      "       0.92588798, 0.92418033, 0.92520492, 0.92418033, 0.92554645,\n",
      "       0.92418033, 0.92554645, 0.92418033, 0.92554645, 0.92349727,\n",
      "       0.92554645, 0.92349727, 0.92452186, 0.92349727, 0.92452186,\n",
      "       0.92349727, 0.92418033, 0.92315574, 0.92349727, 0.92247268,\n",
      "       0.92315574, 0.92247268, 0.92315574, 0.92213115, 0.92315574,\n",
      "       0.92247268, 0.92315574, 0.92213115, 0.92315574, 0.92213115,\n",
      "       0.92315574, 0.92213115, 0.92281421, 0.92213115, 0.92281421,\n",
      "       0.92213115, 0.92281421, 0.92213115, 0.92281421, 0.92178962,\n",
      "       0.92281421, 0.92178962, 0.92281421, 0.9204235 , 0.92281421,\n",
      "       0.92008197, 0.92281421, 0.92008197, 0.92247268, 0.92008197,\n",
      "       0.92247268, 0.92008197, 0.92247268, 0.92008197, 0.92247268,\n",
      "       0.91974044, 0.92178962, 0.91939891, 0.92178962, 0.91939891,\n",
      "       0.92178962, 0.91939891, 0.92178962, 0.91939891, 0.92178962]), 'std_test_score': array([0.00664888, 0.00781798, 0.00664888, 0.00744347, 0.00664888,\n",
      "       0.00744347, 0.00689857, 0.00689857, 0.00689857, 0.00725299,\n",
      "       0.00689857, 0.00725299, 0.0075755 , 0.00725299, 0.0075755 ,\n",
      "       0.00725299, 0.0075755 , 0.00686467, 0.0075755 , 0.00686467,\n",
      "       0.0075755 , 0.00686467, 0.0075755 , 0.00657833, 0.00725299,\n",
      "       0.00657833, 0.00725299, 0.00657833, 0.00744347, 0.00696587,\n",
      "       0.00744347, 0.00696587, 0.00716399, 0.00657833, 0.00651598,\n",
      "       0.00657833, 0.00651598, 0.00664888, 0.00651598, 0.00644398,\n",
      "       0.00651598, 0.00644398, 0.00651598, 0.00644398, 0.00610948,\n",
      "       0.00644398, 0.00610948, 0.00628824, 0.00610948, 0.00628824,\n",
      "       0.00610948, 0.00599383, 0.00598409, 0.00703253, 0.006362  ,\n",
      "       0.0075678 , 0.006362  , 0.0075678 , 0.00587591, 0.0075678 ,\n",
      "       0.00549641, 0.0075678 , 0.00537842, 0.0075678 , 0.00537842,\n",
      "       0.0075678 , 0.00537842, 0.00763684, 0.00537842, 0.00763684,\n",
      "       0.00537842, 0.00763684, 0.00537842, 0.00763684, 0.00574542,\n",
      "       0.00811089, 0.00574542, 0.00811089, 0.00718838, 0.00811089,\n",
      "       0.00672736, 0.00811089, 0.00672736, 0.00787003, 0.00672736,\n",
      "       0.00787003, 0.00672736, 0.00787003, 0.00672736, 0.00787003,\n",
      "       0.00692388, 0.00798772, 0.00735678, 0.00798772, 0.00735678,\n",
      "       0.00798772, 0.00735678, 0.00798772, 0.00735678, 0.00798772]), 'rank_test_score': array([12,  3, 12,  1, 12,  1, 18,  4, 18,  5, 18,  5, 25,  5, 25,  5, 25,\n",
      "        9, 25,  9, 25,  9, 25, 12, 35, 12, 35, 12, 35, 18, 35, 18, 40, 23,\n",
      "       43, 23, 43, 35, 43, 25, 43, 25, 43, 25, 49, 25, 49, 41, 49, 41, 49,\n",
      "       43, 54, 49, 69, 54, 69, 54, 76, 54, 69, 54, 76, 54, 76, 54, 76, 61,\n",
      "       76, 61, 76, 61, 76, 61, 83, 61, 83, 61, 90, 61, 91, 61, 91, 69, 91,\n",
      "       69, 91, 69, 91, 69, 96, 83, 97, 83, 97, 83, 97, 83, 97, 83],\n",
      "      dtype=int32)} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gscv.fit(Xtrain, ytrain)\n",
    "\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_estimator_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_score_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_params_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.cv_results_, \"\\n\")\n",
    "print (\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9290586630286494\n",
      "[[312  51]\n",
      " [  1 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92       363\n",
      "           1       0.88      1.00      0.93       370\n",
      "\n",
      "    accuracy                           0.93       733\n",
      "   macro avg       0.94      0.93      0.93       733\n",
      "weighted avg       0.94      0.93      0.93       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate best_estimator_ on test data\n",
    "\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.93\n",
      "Precision for class 1: 0.88\n",
      "Precision for class 0: 1.0\n",
      "Recall for class 1: 1.0\n",
      "Recall for class 0: 0.86\n",
      "F1 Score for class 1: 0.94\n",
      "F1 Score for class 0: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "TN, FP, FN, TP = metrics.confusion_matrix(y_true=ytest, y_pred=ypred).ravel()\n",
    "overall_accuracy=round((TN+TP)/(TN+FP+FN+TP),2)\n",
    "print(\"Overall Accuracy:\",overall_accuracy)\n",
    "\n",
    "precision1=round(TP/(TP+FP),2)\n",
    "print(\"Precision for class 1:\",precision1)\n",
    "\n",
    "precision0=round(TN/(TN+FN),2)\n",
    "print(\"Precision for class 0:\",precision0)\n",
    "\n",
    "recall1=round(TP/(TP+FN),2)\n",
    "print(\"Recall for class 1:\",recall1)\n",
    "\n",
    "recall0=round(TN/(TN+FP),2)\n",
    "print(\"Recall for class 0:\",recall0)\n",
    "\n",
    "F1Score1=round((2*precision1*recall1)/(precision1+recall1),2)\n",
    "print(\"F1 Score for class 1:\",F1Score1)\n",
    "\n",
    "F1Score0=round((2*precision0*recall0)/(precision0+recall0),2)\n",
    "print(\"F1 Score for class 0:\",F1Score0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
